{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 16bit Quantization in CMSIS NN (per-tensor)\n",
    "\n",
    "\n",
    "## Mathematic\n",
    "\n",
    "$range: [-2^{15}, 2^{15} - 1]$\n",
    "\n",
    "**$x$ denotes weight / bias / tensor**\n",
    "\n",
    "$k = 15 - \\lceil{log_2(max|x|)}\\rceil$\n",
    "\n",
    "$x_q = round(x \\times 2^{k})$ \n",
    "\n",
    "\n",
    "\n",
    "**Get float $x^{'}$ from quantized $x_q$:**\n",
    "\n",
    "$x^{'} = \\frac {x_q} {2^k} $\n",
    "\n",
    "**integer only calculation**\n",
    "\n",
    "weight: $w_q = w^{'} \\times 2^{k_w}$\n",
    "\n",
    "bias: $b_q = b^{'} \\times 2^{k_b}$\n",
    "\n",
    "input tensor: $x_q = x^{'} \\times 2^{k_x}$\n",
    "\n",
    "output tensor: $o_q = o^{'} \\times 2^{k_o}$\n",
    "\n",
    "**floating point:** $o^{'} = w^{'} \\times x^{'} + b^{'}$\n",
    "\n",
    "we need to get $o^{'}$ from $w_q$, $x_q$ and $b_q$\n",
    "\n",
    "\n",
    "$w_q \\times x_q + b_q << b_{lshift}= w^{'} \\times x^{'} \\times 2^{k_w + k_x} + b^{'} \\times 2 ^{k_b + b_{lshift}}$\n",
    "\n",
    "let $b_{lshift} = k_x + k_w - k_b$\n",
    "\n",
    "$w_q \\times x_q + b_q << b_{lshift}= {(w^{'} \\times x^{'} + b^{'})} \\times 2^{k_w + k_x}$\n",
    "\n",
    "let $o_{rshift} = k_x + k_w - k_o$\n",
    "\n",
    "($w_q \\times x_q + b_q << b_{lshift}) >> o_{rshift}= {(w^{'} \\times x^{'} + b^{'})} \\times 2^{k_w + k_x-o_{rshift}}=o^{'} \\times 2^{k_o} = o_q$\n",
    "\n",
    "**to quantize a network, we need to know:**\n",
    "1. bias left shift($b_{lshift}$) for each layer\n",
    "2. output right shift ($o_{rshift}$) for each layer\n",
    "3. input and output quantization format\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:\n",
      "[-2.3053369  -1.91560495 -0.89864258 -1.81937768 -1.60085279  0.15882521\n",
      "  1.6689202   2.14076174  1.40368275  2.07776417  0.19306908  1.98640321\n",
      " -1.98940858 -2.06382312 -2.35358251  0.55091488 -1.79072939  2.30323224\n",
      " -1.24396121 -1.496369  ]\n",
      "Quantized x:\n",
      "[-18885. -15693.  -7362. -14904. -13114.   1301.  13672.  17537.  11499.\n",
      "  17021.   1582.  16273. -16297. -16907. -19281.   4513. -14670.  18868.\n",
      " -10191. -12258.]\n",
      "Quantization error:\n",
      "[-3.90466010e-05  4.44653465e-05  3.90619017e-05 -4.17377855e-05\n",
      " -2.27088437e-05  1.17307267e-05 -2.51088445e-05  1.46659531e-05\n",
      " -3.77139214e-06  5.38292173e-06 -4.61510862e-05 -4.69879500e-05\n",
      " -2.86957579e-05  1.96485445e-05  5.51880863e-05  1.15563292e-05\n",
      "  4.20913436e-05  9.58656843e-06  5.73471951e-05 -3.11141335e-05]\n"
     ]
    }
   ],
   "source": [
    "# quantize a random array\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "x = (np.random.rand(20) * 5 - 2.5)\n",
    "\n",
    "frac_bits = 15 - np.ceil(np.log2(np.max(np.abs(x))))\n",
    "x_q = np.round(x * 2 ** frac_bits)\n",
    "x_f = x_q / 2 ** frac_bits\n",
    "print(\"x:\")\n",
    "print(x)\n",
    "print(\"Quantized x:\")\n",
    "print(x_q)\n",
    "print(\"Quantization error:\")\n",
    "print(x - x_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In practice\n",
    "1. quantize weight and bias, find $max|w|$ and $max|b|$ to compute $k_w$ and $k_b$, save the quantized weight and bias.\n",
    "\n",
    "2. run the model on a testset to find $max|x|$ of each intermediate tensor, and then compute $k_a$\n",
    "\n",
    "3. calculate $b_{lshift}$ and $o_{rshift}$ for each layer.\n",
    "\n",
    "$b_{lshift} = k_x + k_w - k_b$\n",
    "\n",
    "$o_{rshift} = k_x + k_w - k_o$\n",
    "\n",
    "## Data format (from a 2D/3D/4D tensor to a flat buffer)\n",
    "\n",
    "In CMSIS NN everything is stored as a 1D array, so before saving quantized weights, you need to convert them to flat buffers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for tensorflow 2.n\n",
    "# Convolutional layer\n",
    "weight_conv_flat = np.moveaxis(weight_conv, 2, 0).flatten(\"F\")\n",
    "\n",
    "# Fully connected layer\n",
    "weight_fc_flat = np.moveaxis(weight_fc_flat, 1, 0).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for intermediate tensor\n",
    "\n",
    "![shape](./assets/shape.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
